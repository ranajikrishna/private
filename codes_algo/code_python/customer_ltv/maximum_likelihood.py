
import sys
import pandas as pd

from lifetimes.datasets import load_dataset
from lifetimes.utils import summary_data_from_transaction_data
from lifetimes.utils import calibration_and_holdout_data
from lifetimes import BetaGeoFitter
from lifetimes.plotting import plot_period_transactions

from sklearn.metrics import mean_squared_error

import seaborn as sns 
import pdb


def get_data():
    transactions = load_dataset(
        filename='CDNOW_sample.txt', 
        header=None, 
        delim_whitespace=True, 
        names=['customer_id', 'customer_index', 'date', 'quantity', 'amount'],
        converters={'date': lambda x: pd.to_datetime(x, format="%Y%m%d")}
    )
    return transactions


def get_rfm(transactions):
    rfm = summary_data_from_transaction_data(transactions=transactions,
                                         customer_id_col='customer_id',
                                         datetime_col='date',
                                         monetary_value_col = 'amount',
                                         observation_period_end=pd.to_datetime('1998-06-30'),
                                         freq='W')
    return rfm

def get_holdout(transactions):
    rfm_cal_holdout = calibration_and_holdout_data(transactions=transactions,
                                               customer_id_col='customer_id', 
                                               datetime_col='date',
                                               monetary_value_col = 'amount',
                                               freq='W',
                                               calibration_period_end='1998-01-01',
                                               observation_period_end='1998-06-30' )
    return rfm_cal_holdout

def bg_nbd_model(rfm_cal_holdout):
    '''
    This method uses maximum likelihood estimate to compute the values of 
    'r, /alpha, a and b'. Refer to section 5 of the paper.
    Note: When estimating the parameters for the population, as done here, we 
    compute the log-likelihood (i.e. sum of individual likelihoods across all
    data points). This function can be expressed as an expectation as follows:
    F = \sum_{i=1}^{m} log(L(x_{i})) => F = (1/m) \sum_{i=1}^{m} log(L(x_{i}))
    (maximising L is the same as maximising (1/m)*F). Using the pebble analogy 
    for probability mass, F = \sum_{i=1}^{m} p(x_{i}) log(L(x_{i})) 
    => F = E{log(L)}.
    '''
    # instantiation of BG-NBD model
    bgf = BetaGeoFitter(penalizer_coef=0.0)

    # fitting of BG-NBD model
    bgf.fit(frequency=rfm_cal_holdout['frequency_cal'], 
        recency=rfm_cal_holdout['recency_cal'], 
        T=rfm_cal_holdout['T_cal'])

    print(bgf.summary)
    return bgf

def examine_model(rfm_cal_holdout, bgf):
    # First, we choose a sample customer. 
    sample_customer = rfm_cal_holdout.iloc[20] 

    # Let's inspect his frequency, recency and T both for the calibration and 
    # observation periods:
    print(sample_customer)
    # ----

    # Let's now compare this “real” number to the prediction generated by BG-NBD. 
    # The following code yields an expected number of transactions the customer 
    # will make in the next 26 weeks (the length of the observation period):


    # This function calculates the conditional expected number of transactions 
    # in the given time length
    n_transactions_pred = bgf.predict(t=26, # we set it to 26 weeks (the length of the observation period)
                                  frequency=sample_customer['frequency_cal'], 
                                  recency=sample_customer['recency_cal'], 
                                  T=sample_customer['T_cal'])

    # We see that the predicted transaction number (0.76 transactions) is 
    # lower than the actual one (3 transactions).
    n_transactions_pred # = 0.7647440846242359
    # ----

    # We can similarly predict the probability that a certain customer is 
    # still active/alive at the end of the calibration period/start of the 
    # observation period)
    alive_prob = bgf.conditional_probability_alive(frequency=sample_customer['frequency_cal'], 
                                               recency=sample_customer['recency_cal'], 
                                               T=sample_customer['T_cal'])
    alive_prob # = 0.57089896
    # Since the customer did make some purchases in the observation period, we 
    # know with absolute certainty that he was active at the end of the calibration 
    # period. As such, the predicted probability of 0.57 is an underestimate.
    # ----

    # Having seen how to make number-of-transactions prediction for one individual, 
    # we can extend the procedure to our *whole* customer base. The resulting predictions 
    # can then be compared with the real transaction data to gauge the accuracy 
    # of our model.
    # The real number of transactions in the observation period, which equals frequency_holdout + 1
    rfm_cal_holdout["n_transactions_holdout_real"]  = rfm_cal_holdout["frequency_holdout"] + 1

    # The predicted number of transactions in the next 26 weeks (length of the observation period)
    rfm_cal_holdout["n_transactions_holdout_pred"] = bgf.predict(t=26, 
                                                    frequency=rfm_cal_holdout['frequency_cal'], 
                                                    recency=rfm_cal_holdout['recency_cal'], 
                                                    T=rfm_cal_holdout['T_cal'])

    # Comparison of the real and predicted transactions
    print(rfm_cal_holdout[["n_transactions_holdout_real", "n_transactions_holdout_pred"]].head())
    # ----

    # If a more rigorous assessment is desired, these two columns can be 
    # subjected to typical regression metrics such as RMSE:
    RMSE = mean_squared_error(y_true = rfm_cal_holdout["n_transactions_holdout_real"],
                          y_pred = rfm_cal_holdout["n_transactions_holdout_pred"],
                          squared = False)

    RMSE # = 1.3536793286521
    
    pdb.set_trace()

    return

def business_application(bgf, rfm_cal_holdout):
    '''
    The probability-of-being-alive p as well as number of purchases in the 
    next k period, can be used to calculate a rough estimate of the customer’s 
    value for the next k periods. This estimate relies on the following two 
    simplistic assumptions:
    [1] The probability-of-being-alive p remains unchanged in the next k periods
    [2] The average value of purchases in the next k periods equals the average 
        purchase values in the observation period.
    '''
    # the predicted number of transactions in the next 10 weeks
    rfm_cal_holdout["n_transactions_10_pred"] = bgf.predict(t=10, 
                                                        frequency=rfm_cal_holdout['frequency_cal'], 
                                                        recency=rfm_cal_holdout['recency_cal'], 
                                                        T=rfm_cal_holdout['T_cal'])

    # the probability of being alive
    rfm_cal_holdout["alive_prob"] = bgf.conditional_probability_alive(frequency=rfm_cal_holdout['frequency_cal'], 
                                                                  recency=rfm_cal_holdout['recency_cal'], 
                                                                  T=rfm_cal_holdout['T_cal'])


    # multiplication of alive probability x number of purchases x average past purchase
    rfm_cal_holdout["value_10_pred"] = rfm_cal_holdout["alive_prob"]* \
                                   rfm_cal_holdout["n_transactions_10_pred"]*\
                                   rfm_cal_holdout["monetary_value_cal"]
                                   
                                     
    rfm_cal_holdout[["value_10_pred", "alive_prob", "n_transactions_10_pred", \
                                                    "monetary_value_cal"]].head()

    rfm_cal_holdout["value_10_pred"].describe()
    # We see that on average, we’d expect customers to spend around $5.18 
    # in the next 10 weeks.
    # ----

    # We plot a histogram to examine spend.We see that a big chunk of our 
    # customers have value_10_pred close to 0. The resulting average of $5.18
    # was driven by a few outliers
    fig, ax = plt.subplots(figsize = (12, 7))
    ax = sns.histplot(rfm_cal_holdout["value_10_pred"], kde=False, binwidth = 2)
    ax.set_title(f'Customer value histogram')
    ax.set_xlabel(r'Customer value estimate for 10 periods ($)')
    ax.set_ylabel(r'Number of customers in each bin')
    ax.set_xlim(-2,20)

    plt.show()
    # ----

    VALUE_10_PRED_THRESHOLD = 10

    # filtering for high-value customers
    rfm_cal_holdout.loc[rfm_cal_holdout["value_10_pred"]>VALUE_10_PRED_THRESHOLD,\
            ["value_10_pred"]]
    

    return 



def main():
    data = get_data()
    rfm = get_rfm(data)
    hold_out = get_holdout(data)
    bgf = bg_nbd_model(hold_out)
    _ = plot_period_transactions(bgf) 
    examine_model(hold_out, bgf)
    business_application(bgf, hold_out)
    
    return

if __name__ == '__main__':
    status = main()
    sys.exit()

